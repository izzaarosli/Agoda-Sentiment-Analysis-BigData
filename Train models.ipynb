{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "93ceea06-2b60-4d54-9f72-d50018474f87",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%python\n",
    "spark.sql(\"GRANT SELECT ON TABLE silver_dataprocessing.default.silver_agoda_reviews_details_2 TO `23104111@siswa365.um.edu.my`\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c6c4c963-2bac-4757-8e12-d22fa7baa0e1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"GRANT SELECT ON TABLE silver_dataprocessing.default.silver_agoda_reviews_details_2 TO `eia190531@siswa365.um.edu.my`\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6364bb40-af1f-424e-86c0-4433bdab6aa1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"GRANT SELECT ON SCHEMA silver_dataprocessing.default TO `eia190531@siswa365.um.edu.my`\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "28107ebc-53cf-4b6f-a835-16350328018d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Train Multiple Models with Hyperparameter\n",
    "import pandas as pd\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import io\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import lit\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Load and convert data\n",
    "df = spark.sql(\"SELECT content_no_emojis, sentiment FROM silver_dataprocessing.default.silver_agoda_reviews_details_2\")\n",
    "pdf = df.toPandas()\n",
    "\n",
    "# TF-IDF\n",
    "vectorizer = TfidfVectorizer(max_features=1000)\n",
    "X = vectorizer.fit_transform(pdf[\"content_no_emojis\"].astype(str))\n",
    "\n",
    "# Encode labels\n",
    "label_map = {\"Positive\": 1, \"Neutral\": 0, \"Negative\": 2}\n",
    "y = pdf[\"sentiment\"].map(label_map)\n",
    "\n",
    "# Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Models\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(C=1.0, penalty='l2', solver='liblinear', max_iter=1000),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=150, max_depth=15, min_samples_split=5, random_state=42),\n",
    "    \"Naive Bayes\": MultinomialNB(alpha=0.5),\n",
    "    \"Linear SVM\": LinearSVC(C=0.8, max_iter=2000)\n",
    "}\n",
    "\n",
    "best_accuracy = 0\n",
    "best_model = None\n",
    "best_model_name = \"\"\n",
    "best_report = \"\"\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred, zero_division=0)\n",
    "\n",
    "    print(f\"=== {name} ===\")\n",
    "    print(\"Accuracy:\", acc)\n",
    "    print(report)\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    if acc > best_accuracy:\n",
    "        best_accuracy = acc\n",
    "        best_model_name = name\n",
    "        best_model = model\n",
    "        best_report = report\n",
    "\n",
    "print(f\"✅ Best model is '{best_model_name}' with accuracy {best_accuracy:.4f}\")\n",
    "\n",
    "\n",
    "# Save best_model to binary in memory\n",
    "model_buffer = io.BytesIO()\n",
    "joblib.dump(best_model, model_buffer)\n",
    "model_bytes = model_buffer.getvalue()\n",
    "\n",
    "# Save vectorizer to binary in memory\n",
    "vectorizer_buffer = io.BytesIO()\n",
    "joblib.dump(vectorizer, vectorizer_buffer)\n",
    "vectorizer_bytes = vectorizer_buffer.getvalue()\n",
    "\n",
    "# Convert to DataFrame and save to Delta as binary\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "model_df = spark.createDataFrame([(model_bytes,)], [\"model_bin\"])\n",
    "model_df.write.mode(\"overwrite\").save(\"dbfs:/models/best_model_bin\")\n",
    "\n",
    "vectorizer_df = spark.createDataFrame([(vectorizer_bytes,)], [\"vectorizer_bin\"])\n",
    "vectorizer_df.write.mode(\"overwrite\").save(\"dbfs:/models/tfidf_vectorizer_bin\")\n",
    "\n",
    "print(\"✅ Model and vectorizer saved to dbfs:/models/\")\n",
    "\n",
    "# Log to MLflow\n",
    "try:\n",
    "    with mlflow.start_run():\n",
    "        mlflow.sklearn.log_model(best_model, \"best_model\")\n",
    "        mlflow.log_param(\"model_name\", best_model_name)\n",
    "        mlflow.log_metric(\"best_accuracy\", best_accuracy)\n",
    "        print(\"✅ Model logged to MLflow (artifact only)\")\n",
    "except Exception as e:\n",
    "    print(f\"⚠️ MLflow logging skipped due to error: {e}\")\n",
    "\n",
    "# Save evaluation report to Delta table\n",
    "report_data = [(best_model_name, float(best_accuracy), best_report)]\n",
    "report_schema = [\"model_name\", \"accuracy\", \"classification_report\"]\n",
    "spark_report_df = spark.createDataFrame(report_data, report_schema)\n",
    "\n",
    "spark_report_df.write.mode(\"overwrite\").format(\"delta\").saveAsTable(\"default.gold_model_results\")\n",
    "print(\"✅ Best model report saved to Delta table: default.gold_model_results\")\n",
    "\n",
    "# Export CSV for Power BI\n",
    "try:\n",
    "    spark_report_df.toPandas().to_csv(\"/dbfs/FileStore/silver_dataprocessing.default.gold_model_results.csv\", index=False)\n",
    "    print(\"✅ Predictions saved to CSV for Power BI.\")\n",
    "except Exception as e:\n",
    "    print(f\"⚠️ Failed to export CSV: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f4070c18-a9cb-4b69-9584-07bf8c6c0d49",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Best model report saved to Delta table: default.gold_model_results\n"
     ]
    }
   ],
   "source": [
    "# ✅ Create a Spark DataFrame with the best model evaluation\n",
    "report_data = [(best_model_name, float(best_accuracy), best_report)]\n",
    "report_schema = [\"model_name\", \"accuracy\", \"classification_report\"]\n",
    "\n",
    "spark_report_df = spark.createDataFrame(report_data, report_schema)\n",
    "\n",
    "# \uD83D\uDCBE Save the report as a Delta table with consistent name\n",
    "spark_report_df.write.mode(\"overwrite\").format(\"delta\").saveAsTable(\"default.gold_model_results\")\n",
    "print(\"✅ Best model report saved to Delta table: default.gold_model_results\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9934268f-eeb7-47fc-bbb6-236996dea825",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Predictions saved temporarily to: /tmp/gold_model_results.csv\n"
     ]
    }
   ],
   "source": [
    "# ✅ Save predictions to a CSV file in DBFS for Power BI\n",
    "csv_temp_path = \"/tmp/gold_model_results.csv\"\n",
    "\n",
    "try:\n",
    "    spark_report_df.toPandas().to_csv(csv_temp_path, index=False)\n",
    "    print(f\"✅ Predictions saved temporarily to: {csv_temp_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"⚠️ Failed to export CSV to /tmp: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c5918162-ab98-49a0-8b25-770f3505e020",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>model_name</th><th>accuracy</th><th>classification_report</th></tr></thead><tbody><tr><td>Linear SVM</td><td>0.8709960508995174</td><td>              precision    recall  f1-score   support\n",
       "\n",
       "           0       0.79      0.83      0.81       368\n",
       "           1       0.93      0.89      0.91      1307\n",
       "           2       0.80      0.85      0.83       604\n",
       "\n",
       "    accuracy                           0.87      2279\n",
       "   macro avg       0.84      0.86      0.85      2279\n",
       "weighted avg       0.87      0.87      0.87      2279\n",
       "</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "Linear SVM",
         0.8709960508995174,
         "              precision    recall  f1-score   support\n\n           0       0.79      0.83      0.81       368\n           1       0.93      0.89      0.91      1307\n           2       0.80      0.85      0.83       604\n\n    accuracy                           0.87      2279\n   macro avg       0.84      0.86      0.85      2279\nweighted avg       0.87      0.87      0.87      2279\n"
        ]
       ],
       "datasetInfos": [
        {
         "name": "_sqldf",
         "schema": {
          "fields": [
           {
            "metadata": {},
            "name": "model_name",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "accuracy",
            "nullable": true,
            "type": "double"
           },
           {
            "metadata": {},
            "name": "classification_report",
            "nullable": true,
            "type": "string"
           }
          ],
          "type": "struct"
         },
         "tableIdentifier": null,
         "typeStr": "pyspark.sql.connect.dataframe.DataFrame"
        }
       ],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "createTempViewForImplicitDf": true,
        "dataframeName": "_sqldf",
        "executionCount": 24
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "model_name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "accuracy",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "classification_report",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "SELECT * FROM default.gold_model_results;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e2b229ce-70b0-43cb-bea8-2e99fd1fd324",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>content_no_emojis</th><th>score</th><th>repliedAt</th></tr></thead><tbody><tr><td>Agoda is a popular hotel booking app known for its wide selection of accommodations worldwide and competitive prices. Whether you’re planning a luxury getaway or a budget trip, Agoda offers great deals with a user-friendly interface that makes booking simple and fast.</td><td>5</td><td>2025-06-03T06:37:34</td></tr><tr><td>DO NOT USE THIS APP OR BOOK WITH AGODA!!! I booked a room and canceled 3 days before and they still charged me even though it says anything before 24hrs can be canceled. I contacted the hotel manager to dispute it and they said they have no record of my booking so agoda stole my money. and they change the prices on you for the hotel listing.</td><td>1</td><td>2025-06-03T05:03:49</td></tr><tr><td>ลงแล้วทำเครื่องค้างๆ เปิดแอพอื่นแล้ว crashed เปิดไม่ได้</td><td>1</td><td>2025-06-03T04:59:45</td></tr><tr><td>PayNow QR Payment does not work. Generated QR code cannot be detected</td><td>1</td><td>2025-06-03T03:59:07</td></tr><tr><td>feedback</td><td>5</td><td>2025-06-03T00:27:34</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "Agoda is a popular hotel booking app known for its wide selection of accommodations worldwide and competitive prices. Whether you’re planning a luxury getaway or a budget trip, Agoda offers great deals with a user-friendly interface that makes booking simple and fast.",
         5,
         "2025-06-03T06:37:34"
        ],
        [
         "DO NOT USE THIS APP OR BOOK WITH AGODA!!! I booked a room and canceled 3 days before and they still charged me even though it says anything before 24hrs can be canceled. I contacted the hotel manager to dispute it and they said they have no record of my booking so agoda stole my money. and they change the prices on you for the hotel listing.",
         1,
         "2025-06-03T05:03:49"
        ],
        [
         "ลงแล้วทำเครื่องค้างๆ เปิดแอพอื่นแล้ว crashed เปิดไม่ได้",
         1,
         "2025-06-03T04:59:45"
        ],
        [
         "PayNow QR Payment does not work. Generated QR code cannot be detected",
         1,
         "2025-06-03T03:59:07"
        ],
        [
         "feedback",
         5,
         "2025-06-03T00:27:34"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "content_no_emojis",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "score",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "repliedAt",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%python\n",
    "# Temporarily test loading latest data instead of yesterday\n",
    "df = (\n",
    "    spark.sql(\"\"\"\n",
    "        SELECT content_no_emojis, score, repliedAt\n",
    "        FROM silver_dataprocessing.default.silver_agoda_reviews_details\n",
    "    \"\"\")\n",
    "    .orderBy(col(\"repliedAt\").desc())\n",
    "    .limit(1000)\n",
    ")\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "19ab1e10-1c52-484e-a50b-5eadc332a3b9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n|replied_date|\n+------------+\n|  2025-06-03|\n+------------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import to_date\n",
    "\n",
    "# Show the most recent repliedAt dates available in your data\n",
    "df_debug = spark.sql(\"\"\"\n",
    "    SELECT DISTINCT to_date(repliedAt) AS replied_date\n",
    "    FROM silver_dataprocessing.default.silver_agoda_reviews_details\n",
    "    ORDER BY replied_date DESC\n",
    "\"\"\")\n",
    "\n",
    "df_debug.show(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5117f9f7-2c8c-49e9-bf75-f4656897fc5c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\uD83D\uDCE6 Loaded 5 rows for Malaysia date: 2025-06-03\n✅ Pretrained model and vectorizer loaded from DBFS.\n✅ Inference report saved as CSV to: dbfs:/FileStore/predicted_sentiments_yesterday.csv\n"
     ]
    }
   ],
   "source": [
    "# ✅ Daily Inference Script: Load new data, predict sentiment using pre-trained model, and save for reporting\n",
    "\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import io\n",
    "from datetime import datetime, timedelta\n",
    "from pyspark.sql.functions import col, to_date, lit\n",
    "from pyspark.sql.types import DateType\n",
    "\n",
    "# Define yesterday's Malaysia date (UTC+8)\n",
    "yesterday_local = datetime.strptime(\"2025-06-03\", \"%Y-%m-%d\").date()  # for manual testing\n",
    "\n",
    "df = (\n",
    "    spark.sql(\"\"\"\n",
    "        SELECT content_no_emojis, score, repliedAt\n",
    "        FROM silver_dataprocessing.default.silver_agoda_reviews_details\n",
    "    \"\"\")\n",
    "    .withColumn(\"replied_date\", to_date(col(\"repliedAt\")))\n",
    "    .filter(col(\"replied_date\") == lit(yesterday_local).cast(DateType()))\n",
    ")\n",
    "\n",
    "row_count = df.count()\n",
    "print(f\"\uD83D\uDCE6 Loaded {row_count} rows for Malaysia date: {yesterday_local}\")\n",
    "\n",
    "if row_count == 0:\n",
    "    print(\"⚠️ No new data available for prediction.\")\n",
    "else:\n",
    "    # \uD83E\uDDEA Convert to Pandas\n",
    "    pdf = df.select(\"content_no_emojis\", \"score\", \"repliedAt\").toPandas()\n",
    "\n",
    "    # ✅ Load model and vectorizer from DBFS binary blobs\n",
    "    try:\n",
    "        model_bytes = spark.read.load(\"dbfs:/models/best_model_bin\").collect()[0][\"model_bin\"]\n",
    "        vectorizer_bytes = spark.read.load(\"dbfs:/models/tfidf_vectorizer_bin\").collect()[0][\"vectorizer_bin\"]\n",
    "\n",
    "        model = joblib.load(io.BytesIO(model_bytes))\n",
    "        vectorizer = joblib.load(io.BytesIO(vectorizer_bytes))\n",
    "\n",
    "        print(\"✅ Pretrained model and vectorizer loaded from DBFS.\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Failed to load model/vectorizer from DBFS: {e}\")\n",
    "        raise\n",
    "\n",
    "    # \uD83E\uDDFC Vectorize input\n",
    "    X = vectorizer.transform(pdf[\"content_no_emojis\"].astype(str))\n",
    "\n",
    "    # \uD83D\uDD2E Predict sentiment\n",
    "    label_map_reverse = {1: \"Positive\", 0: \"Neutral\", 2: \"Negative\"}\n",
    "    y_pred = model.predict(X)\n",
    "    pdf[\"predicted_sentiment\"] = pd.Series(y_pred).map(label_map_reverse)\n",
    "\n",
    "    # \uD83D\uDCBE Convert to Spark DataFrame\n",
    "    result_df = spark.createDataFrame(pdf)\n",
    "\n",
    "    # Save to DBFS as Spark DataFrame CSV \n",
    "    output_path = \"dbfs:/FileStore/predicted_sentiments_yesterday.csv\"\n",
    "\n",
    "try:\n",
    "    result_df.write.mode(\"overwrite\").option(\"header\", \"true\").csv(output_path)\n",
    "    print(f\"✅ Inference report saved as CSV to: {output_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"⚠️ Failed to save CSV to DBFS: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9983149d-9a28-4fca-8b00-51f7507ca6ca",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----+-------------------+-------------------+\n|content_no_emojis                                                                                                                                                                                                                                                                                                                                      |score|repliedAt          |predicted_sentiment|\n+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----+-------------------+-------------------+\n|DO NOT USE THIS APP OR BOOK WITH AGODA!!! I booked a room and canceled 3 days before and they still charged me even though it says anything before 24hrs can be canceled. I contacted the hotel manager to dispute it and they said they have no record of my booking so agoda stole my money. and they change the prices on you for the hotel listing.|1    |2025-06-03 05:03:49|Negative           |\n|Agoda is a popular hotel booking app known for its wide selection of accommodations worldwide and competitive prices. Whether you’re planning a luxury getaway or a budget trip, Agoda offers great deals with a user-friendly interface that makes booking simple and fast.                                                                           |5    |2025-06-03 06:37:34|Positive           |\n|ลงแล้วทำเครื่องค้างๆ เปิดแอพอื่นแล้ว crashed เปิดไม่ได้                                                                                                                                                                                                                                                                                                |1    |2025-06-03 04:59:45|Neutral            |\n|PayNow QR Payment does not work. Generated QR code cannot be detected                                                                                                                                                                                                                                                                                  |1    |2025-06-03 03:59:07|Neutral            |\n|feedback                                                                                                                                                                                                                                                                                                                                               |5    |2025-06-03 00:27:34|Neutral            |\n+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----+-------------------+-------------------+\n\n✅ Loaded 5 rows from predicted_sentiments_yesterday.csv\n"
     ]
    }
   ],
   "source": [
    "# ✅ Load predicted sentiment CSV from DBFS\n",
    "df = (\n",
    "    spark.read\n",
    "    .option(\"header\", \"true\")\n",
    "    .option(\"inferSchema\", \"true\")\n",
    "    .csv(\"dbfs:/FileStore/predicted_sentiments_yesterday.csv\")\n",
    ")\n",
    "\n",
    "# Show a few rows\n",
    "df.show(truncate=False)\n",
    "\n",
    "# Count the number of rows\n",
    "print(f\"✅ Loaded {df.count()} rows from predicted_sentiments_yesterday.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 4827045939842803,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Train models",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}