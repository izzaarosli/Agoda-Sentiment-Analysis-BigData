{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e2368a70-2c63-4ad1-be1a-7455b73aa5d1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "1. Data Ingestion & Cleaning Monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "491adf36-f655-4d01-b656-8df5952427c7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: py4j\nVersion: 0.10.9.9\nSummary: Enables Python programs to dynamically access arbitrary Java objects\nHome-page: https://www.py4j.org/\nAuthor: Barthelemy Dagenais\nAuthor-email: barthelemy@infobart.com\nLicense: BSD License\nLocation: /local_disk0/.ephemeral_nfs/envs/pythonEnv-aaa948bb-df6c-4543-b569-665a46d7eef7/lib/python3.11/site-packages\nRequires: \nRequired-by: databricks-connect, pyspark\n"
     ]
    }
   ],
   "source": [
    "!pip show py4j\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d3b9dd3e-8e9e-412b-b42e-611f7742b1db",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Quality Report:\n  Total raw records: 11496\n  Records after cleaning: 11387\n  Dropped records: 109\n  Duplicate records: 0\n  Missing 'content' records: 0\n\nLanguage distribution:\nEnglish                    9775\nIndonesian                  423\nSlovak                      131\nAfrikaans                   125\nTagalog                     105\nFrench                      101\nItalian                      86\nRomanian                     66\nDanish                       63\nNorwegian                    59\nGerman                       58\nSpanish                      43\nDutch                        38\nSomali                       36\nWelsh                        30\nEstonian                     30\nArabic                       26\nCatalan                      24\nPolish                       23\nPortuguese                   21\nVietnamese                   21\nThai                         16\nFinnish                      12\nSwedish                      11\nCroatian                     11\nSwahili (macrolanguage)      10\nAlbanian                     10\nTurkish                       5\nSlovenian                     5\nLatvian                       3\nHindi                         3\nKorean                        3\nCzech                         3\nHungarian                     3\nNepali (macrolanguage)        2\nJapanese                      2\nRussian                       1\nLithuanian                    1\nMalayalam                     1\nBengali                       1\nName: language, dtype: int64\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>Step</th><th>Time</th><th>CPU_Usage_Percent</th><th>Memory_Used_GB</th><th>Duration_Sec</th><th>Notes</th></tr></thead><tbody><tr><td>File Loading Summary</td><td>2025-06-06 22:08:34</td><td>31.1</td><td>11.0</td><td>390.46</td><td>Files loaded: 1, failed: 383, total records: 11496, total load time: 388.46s</td></tr><tr><td>Clean & Detect Language</td><td>2025-06-06 22:09:20</td><td>21.9</td><td>11.0</td><td>45.68</td><td>Cleaned records: 11387</td></tr><tr><td>Data Quality Monitoring</td><td>2025-06-06 22:09:21</td><td>28.5</td><td>11.01</td><td>1.0</td><td>Raw: 11496, Cleaned: 11387, Dropped: 109, Duplicates: 0, Missing content: 0</td></tr><tr><td>Save to Evaluation Table</td><td>2025-06-06 22:09:25</td><td>30.1</td><td>11.05</td><td>3.67</td><td>Saved to evaluation.silver_reviews_copy</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "File Loading Summary",
         "2025-06-06 22:08:34",
         31.1,
         11.0,
         390.46,
         "Files loaded: 1, failed: 383, total records: 11496, total load time: 388.46s"
        ],
        [
         "Clean & Detect Language",
         "2025-06-06 22:09:20",
         21.9,
         11.0,
         45.68,
         "Cleaned records: 11387"
        ],
        [
         "Data Quality Monitoring",
         "2025-06-06 22:09:21",
         28.5,
         11.01,
         1.0,
         "Raw: 11496, Cleaned: 11387, Dropped: 109, Duplicates: 0, Missing content: 0"
        ],
        [
         "Save to Evaluation Table",
         "2025-06-06 22:09:25",
         30.1,
         11.05,
         3.67,
         "Saved to evaluation.silver_reviews_copy"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "Step",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Time",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "CPU_Usage_Percent",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "Memory_Used_GB",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "Duration_Sec",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "Notes",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation logs saved to CSV and Delta table.\n"
     ]
    }
   ],
   "source": [
    "# %pip install emoji langdetect langcodes iso-639 requests psutil pyspark\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "import emoji\n",
    "import psutil\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "from langdetect import detect, DetectorFactory\n",
    "from iso639 import languages\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "DetectorFactory.seed = 42  # consistent lang detect\n",
    "\n",
    "# Evaluation log storage\n",
    "eval_log = []\n",
    "\n",
    "def log_evaluation(step, start_time, notes=\"\"):\n",
    "    cpu = psutil.cpu_percent(interval=1)\n",
    "    mem = psutil.virtual_memory().used / (1024 ** 3)\n",
    "    duration = round(time.time() - start_time, 2)\n",
    "    eval_log.append({\n",
    "        \"Step\": step,\n",
    "        \"Time\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "        \"CPU_Usage_Percent\": cpu,           \n",
    "        \"Memory_Used_GB\": round(mem, 2),   \n",
    "        \"Duration_Sec\": duration,\n",
    "        \"Notes\": notes\n",
    "    })\n",
    "\n",
    "# Constants and URLs\n",
    "container_url = \"https://wqd7007.blob.core.windows.net/bronze-webscrape\"\n",
    "sas_token = (\"sv=2024-11-04&ss=bfqt&srt=sco&sp=rwdlacupiytfx&se=2026-06-30T20:37:08Z\"\n",
    "             \"&st=2025-05-18T12:37:08Z&spr=https&sig=ztkYcXLKHQ9nC5CE3PThs1OY%2FTDHHzSZ8JD4J6JUc1s%3D\")\n",
    "\n",
    "# Date range for loading daily files\n",
    "start_date = datetime(2024, 5, 1)\n",
    "end_date = datetime(2025, 5, 18)\n",
    "date_range = [(start_date + timedelta(days=i)).strftime('%Y%m%d') for i in range((end_date - start_date).days + 1)]\n",
    "\n",
    "all_data = []\n",
    "loaded_files = 0\n",
    "failed_files = 0\n",
    "\n",
    "# Unified load start time for all files\n",
    "overall_start_time = time.time()\n",
    "\n",
    "# Load combined file first\n",
    "combined_filename = \"agoda_reviews_20240501_to_20250518.json\"\n",
    "combined_url = f\"{container_url}/{combined_filename}?{sas_token}\"\n",
    "\n",
    "response = requests.get(combined_url)\n",
    "if response.status_code == 200:\n",
    "    try:\n",
    "        data = response.json()\n",
    "        if isinstance(data, list) and data:\n",
    "            all_data.extend(data)\n",
    "        loaded_files += 1\n",
    "    except Exception as e:\n",
    "        failed_files += 1\n",
    "else:\n",
    "    failed_files += 1\n",
    "\n",
    "# Load daily files one by one \n",
    "for date_str in date_range:\n",
    "    # Uncomment below if want to skip combined file date range to avoid duplicates\n",
    "    # if \"20240501\" <= date_str <= \"20250518\":\n",
    "    #     continue\n",
    "\n",
    "    file_url = f\"{container_url}/agoda_reviews_{date_str}.json?{sas_token}\"\n",
    "    try:\n",
    "        response = requests.get(file_url)\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            if isinstance(data, list) and data:\n",
    "                all_data.extend(data)\n",
    "                loaded_files += 1\n",
    "            else:\n",
    "                failed_files += 1\n",
    "        else:\n",
    "            failed_files += 1\n",
    "    except Exception:\n",
    "        failed_files += 1\n",
    "\n",
    "total_load_duration = time.time() - overall_start_time\n",
    "cpu = psutil.cpu_percent(interval=1)\n",
    "mem = psutil.virtual_memory().used / (1024 ** 3)\n",
    "log_evaluation(\"File Loading Summary\", overall_start_time,\n",
    "               f\"Files loaded: {loaded_files}, failed: {failed_files}, total records: {len(all_data)}, total load time: {total_load_duration:.2f}s\")\n",
    "\n",
    "# DataFrame creation and cleaning\n",
    "start_time = time.time()\n",
    "df = pd.DataFrame(all_data)\n",
    "if df.empty or \"content\" not in df.columns:\n",
    "    raise ValueError(\"No valid review data found.\")\n",
    "\n",
    "df.drop(columns=['userImage', 'reviewCreatedVersion'], errors='ignore', inplace=True)\n",
    "\n",
    "def remove_emojis(text):\n",
    "    return emoji.replace_emoji(str(text), replace='').strip()\n",
    "\n",
    "df['content_no_emojis'] = df['content'].apply(remove_emojis)\n",
    "\n",
    "def detect_language(text):\n",
    "    try:\n",
    "        return detect(str(text))\n",
    "    except:\n",
    "        return \"Unknown\"\n",
    "\n",
    "df['language_code'] = df['content_no_emojis'].astype(str).apply(detect_language)\n",
    "\n",
    "def detect_language_name(code):\n",
    "    try:\n",
    "        return languages.get(part1=code).name\n",
    "    except:\n",
    "        return \"Unknown\"\n",
    "\n",
    "df['language'] = df['language_code'].apply(detect_language_name)\n",
    "\n",
    "# Heuristic English correction\n",
    "english_terms = ['amazing','awesome','great','good','love','nice','perfect','helpful','worst','bad','excellent','recommended']\n",
    "not_en = df[\"language_code\"] != \"en\"\n",
    "for term in english_terms:\n",
    "    df.loc[not_en & df['content_no_emojis'].str.lower().str.contains(term, na=False), 'language_code'] = 'en'\n",
    "\n",
    "df['language'] = df['language_code'].apply(detect_language_name)\n",
    "\n",
    "df_cleaned = df[df['language'] != \"Unknown\"].reset_index(drop=True)\n",
    "log_evaluation(\"Clean & Detect Language\", start_time, f\"Cleaned records: {len(df_cleaned)}\")\n",
    "\n",
    "# Data quality metrics\n",
    "raw_count = len(all_data)\n",
    "cleaned_count = len(df_cleaned)\n",
    "dropped_count = raw_count - cleaned_count\n",
    "duplicate_count = df_cleaned.duplicated().sum()\n",
    "missing_content_count = df_cleaned['content'].isnull().sum()\n",
    "lang_dist = df_cleaned['language'].value_counts()\n",
    "\n",
    "print(f\"Data Quality Report:\")\n",
    "print(f\"  Total raw records: {raw_count}\")\n",
    "print(f\"  Records after cleaning: {cleaned_count}\")\n",
    "print(f\"  Dropped records: {dropped_count}\")\n",
    "print(f\"  Duplicate records: {duplicate_count}\")\n",
    "print(f\"  Missing 'content' records: {missing_content_count}\")\n",
    "print(\"\\nLanguage distribution:\")\n",
    "print(lang_dist)\n",
    "\n",
    "log_evaluation(\"Data Quality Monitoring\", time.time(),\n",
    "               f\"Raw: {raw_count}, Cleaned: {cleaned_count}, Dropped: {dropped_count}, \"\n",
    "               f\"Duplicates: {duplicate_count}, Missing content: {missing_content_count}\")\n",
    "\n",
    "# Save cleaned data to Delta table\n",
    "start_time = time.time()\n",
    "spark_df = spark.createDataFrame(df_cleaned)\n",
    "spark.sql(\"CREATE SCHEMA IF NOT EXISTS evaluation\")\n",
    "spark_df.write.format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"overwriteSchema\", \"true\") \\\n",
    "    .saveAsTable(\"evaluation.silver_reviews_copy\")\n",
    "log_evaluation(\"Save to Evaluation Table\", start_time, \"Saved to evaluation.silver_reviews_copy\")\n",
    "\n",
    "# Show evaluation summary table\n",
    "eval_summary_df = pd.DataFrame(eval_log)\n",
    "\n",
    "# Clean column names for Delta\n",
    "eval_summary_df.columns = eval_summary_df.columns.str.replace(r'[ ,;{}()\\n\\t=%]', '_', regex=True)\n",
    "\n",
    "display(spark.createDataFrame(eval_summary_df))\n",
    "\n",
    "# Save evaluation logs to CSV and Delta table\n",
    "eval_df = eval_summary_df.copy()\n",
    "eval_df.to_csv(\"evaluation_log.csv\", index=False)\n",
    "spark.createDataFrame(eval_df).write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"evaluation.pipeline_logs\")\n",
    "\n",
    "print(\"Evaluation logs saved to CSV and Delta table.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "82784d8b-ba5a-45e0-9383-6ccec4134f98",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "2. Sentiment Analysis Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1ff50b6c-8e1d-4aab-8c5d-585b1ec8b29c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /local_disk0/.ephemeral_nfs/envs/pythonEnv-aaa948bb-df6c-4543-b569-665a46d7eef7/lib/python3.11/site-packages (3.9.1)\nRequirement already satisfied: psutil in /databricks/python3/lib/python3.11/site-packages (5.9.0)\nRequirement already satisfied: click in /databricks/python3/lib/python3.11/site-packages (from nltk) (8.0.4)\nRequirement already satisfied: joblib in /databricks/python3/lib/python3.11/site-packages (from nltk) (1.2.0)\nRequirement already satisfied: regex>=2021.8.3 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-aaa948bb-df6c-4543-b569-665a46d7eef7/lib/python3.11/site-packages (from nltk) (2024.11.6)\nRequirement already satisfied: tqdm in /local_disk0/.ephemeral_nfs/envs/pythonEnv-aaa948bb-df6c-4543-b569-665a46d7eef7/lib/python3.11/site-packages (from nltk) (4.67.1)\n\u001B[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001B[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to /home/spark-aaa948bb-\n[nltk_data]     df6c-4543-b569-66/nltk_data...\n[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment Analysis completed in 33.82 sec, CPU usage: 27.5%, Memory used: 10.84 GB\nSentiment analysis results and evaluation logs saved to the evaluation database.\n"
     ]
    }
   ],
   "source": [
    "# Install required package \n",
    "%pip install nltk psutil\n",
    "\n",
    "import nltk\n",
    "import time\n",
    "import psutil\n",
    "from datetime import datetime\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from pyspark.sql.functions import udf, when\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "# Download VADER lexicon \n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "# Initialize VADER sentiment analyzer\n",
    "analyser = SentimentIntensityAnalyzer()\n",
    "\n",
    "def sentiment_analyzer_scores(sentence):\n",
    "    return analyser.polarity_scores(sentence)\n",
    "\n",
    "# Define Spark UDF for sentiment scoring\n",
    "sentiment_udf = udf(lambda x: sentiment_analyzer_scores(str(x)), MapType(StringType(), FloatType()))\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Load cleaned review data from your independent evaluation table\n",
    "df_sentiment = spark.sql(\"SELECT * FROM evaluation.silver_reviews_copy\")\n",
    "\n",
    "# Apply VADER sentiment analysis UDF\n",
    "df_sentiment = df_sentiment.withColumn('vader_scores', sentiment_udf(df_sentiment['content_no_emojis']))\n",
    "df_sentiment = df_sentiment.withColumn('compound', df_sentiment['vader_scores']['compound'])\n",
    "\n",
    "# Classify sentiment based on compound score thresholds\n",
    "df_sentiment = df_sentiment.withColumn(\n",
    "    'sentiment',\n",
    "    when(df_sentiment['compound'] >= 0.05, 'Positive')\n",
    "    .when(df_sentiment['compound'] <= -0.05, 'Negative')\n",
    "    .otherwise('Neutral')\n",
    ")\n",
    "\n",
    "# Drop intermediate score columns for clean output\n",
    "df_sentiment = df_sentiment.drop('vader_scores', 'compound')\n",
    "\n",
    "# Performance monitoring: record duration, CPU, and memory usage\n",
    "duration = round(time.time() - start_time, 2)\n",
    "cpu = psutil.cpu_percent(interval=1)\n",
    "mem = psutil.virtual_memory().used / (1024 ** 3)\n",
    "\n",
    "print(f\"Sentiment Analysis completed in {duration} sec, CPU usage: {cpu}%, Memory used: {mem:.2f} GB\")\n",
    "\n",
    "# Prepare evaluation log\n",
    "eval_log = [{\n",
    "    \"Step\": \"Sentiment Analysis\",\n",
    "    \"Time\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "    \"CPU_Usage_Percent\": cpu,\n",
    "    \"Memory_Used_GB\": round(mem, 2),\n",
    "    \"Duration_Sec\": duration,\n",
    "    \"Notes\": f\"Processed {df_sentiment.count()} records\"\n",
    "}]\n",
    "\n",
    "# Save sentiment results to your independent evaluation sentiment table\n",
    "df_sentiment.write.format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"overwriteSchema\", \"true\") \\\n",
    "    .saveAsTable(\"evaluation.silver_reviews_sentiment\")\n",
    "\n",
    "# Save evaluation logs to a separate table for monitoring\n",
    "eval_df = spark.createDataFrame(eval_log)\n",
    "eval_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"evaluation.sentiment_analysis_logs\")\n",
    "\n",
    "print(\"Sentiment analysis results and evaluation logs saved to the evaluation database.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bec145d1-38a6-416c-b418-dadde07d0df1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "3. Model Training Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ec17e6e8-8568-473c-ae54-08af816e57fb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>col_name</th><th>data_type</th><th>comment</th></tr></thead><tbody><tr><td>reviewId</td><td>string</td><td>null</td></tr><tr><td>userName</td><td>string</td><td>null</td></tr><tr><td>content</td><td>string</td><td>null</td></tr><tr><td>score</td><td>bigint</td><td>null</td></tr><tr><td>thumbsUpCount</td><td>bigint</td><td>null</td></tr><tr><td>at</td><td>string</td><td>null</td></tr><tr><td>replyContent</td><td>string</td><td>null</td></tr><tr><td>repliedAt</td><td>string</td><td>null</td></tr><tr><td>appVersion</td><td>string</td><td>null</td></tr><tr><td>content_no_emojis</td><td>string</td><td>null</td></tr><tr><td>language_code</td><td>string</td><td>null</td></tr><tr><td>language</td><td>string</td><td>null</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "reviewId",
         "string",
         null
        ],
        [
         "userName",
         "string",
         null
        ],
        [
         "content",
         "string",
         null
        ],
        [
         "score",
         "bigint",
         null
        ],
        [
         "thumbsUpCount",
         "bigint",
         null
        ],
        [
         "at",
         "string",
         null
        ],
        [
         "replyContent",
         "string",
         null
        ],
        [
         "repliedAt",
         "string",
         null
        ],
        [
         "appVersion",
         "string",
         null
        ],
        [
         "content_no_emojis",
         "string",
         null
        ],
        [
         "language_code",
         "string",
         null
        ],
        [
         "language",
         "string",
         null
        ]
       ],
       "datasetInfos": [
        {
         "name": "_sqldf",
         "schema": {
          "fields": [
           {
            "metadata": {},
            "name": "col_name",
            "nullable": false,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "data_type",
            "nullable": false,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "comment",
            "nullable": true,
            "type": "string"
           }
          ],
          "type": "struct"
         },
         "tableIdentifier": null,
         "typeStr": "pyspark.sql.connect.dataframe.DataFrame"
        }
       ],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "createTempViewForImplicitDf": true,
        "dataframeName": "_sqldf",
        "executionCount": 216
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "col_name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "data_type",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "comment",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "DESCRIBE TABLE evaluation.silver_reviews_copy;\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1496e4b7-a320-4fb4-b894-2af13f1d7d1f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Logistic Regression ===\nAccuracy: 0.8964458095655989\n              precision    recall  f1-score   support\n\n           0       0.78      0.84      0.81       336\n           1       0.96      0.93      0.94      1497\n           2       0.80      0.84      0.82       446\n\n    accuracy                           0.90      2279\n   macro avg       0.85      0.87      0.86      2279\nweighted avg       0.90      0.90      0.90      2279\n\n--------------------------------------------------\n=== Random Forest ===\nAccuracy: 0.759104870557262\n              precision    recall  f1-score   support\n\n           0       0.63      0.04      0.07       336\n           1       0.77      0.93      0.84      1497\n           2       0.73      0.74      0.73       446\n\n    accuracy                           0.76      2279\n   macro avg       0.71      0.57      0.55      2279\nweighted avg       0.74      0.76      0.71      2279\n\n--------------------------------------------------\n=== Naive Bayes ===\nAccuracy: 0.8108819657744625\n              precision    recall  f1-score   support\n\n           0       0.78      0.26      0.39       336\n           1       0.86      0.92      0.89      1497\n           2       0.68      0.86      0.76       446\n\n    accuracy                           0.81      2279\n   macro avg       0.77      0.68      0.68      2279\nweighted avg       0.81      0.81      0.79      2279\n\n--------------------------------------------------\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/databricks/python/lib/python3.11/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n  warnings.warn(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Linear SVM ===\nAccuracy: 0.9021500658183413\n              precision    recall  f1-score   support\n\n           0       0.79      0.87      0.83       336\n           1       0.95      0.93      0.94      1497\n           2       0.83      0.83      0.83       446\n\n    accuracy                           0.90      2279\n   macro avg       0.86      0.88      0.87      2279\nweighted avg       0.90      0.90      0.90      2279\n\n--------------------------------------------------\nâœ… Evaluation logs written to Delta table: evaluation.model_training_logs\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import psutil\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Start Spark session\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "# Initialize evaluation log\n",
    "eval_log = []\n",
    "\n",
    "# Step 1: Data Loading\n",
    "start_time = time.time()\n",
    "df = spark.sql(\"SELECT content_no_emojis, sentiment FROM silver_dataprocessing.default.silver_agoda_reviews_details_2\")\n",
    "pdf = df.toPandas()\n",
    "load_duration = round(time.time() - start_time, 2)\n",
    "eval_log.append({\n",
    "    \"Step\": \"Load Data\",\n",
    "    \"Time\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "    \"CPU_Usage_Percent\": psutil.cpu_percent(interval=1),\n",
    "    \"Memory_Used_GB\": round(psutil.virtual_memory().used / (1024 ** 3), 2),\n",
    "    \"Duration_Sec\": load_duration,\n",
    "    \"Notes\": f\"Loaded {len(pdf)} rows\"\n",
    "})\n",
    "\n",
    "# Step 2: TF-IDF Vectorization\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vector_start = time.time()\n",
    "vectorizer = TfidfVectorizer(max_features=1000)\n",
    "X = vectorizer.fit_transform(pdf[\"content_no_emojis\"].astype(str))\n",
    "vector_duration = round(time.time() - vector_start, 2)\n",
    "eval_log.append({\n",
    "    \"Step\": \"TF-IDF Vectorization\",\n",
    "    \"Time\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "    \"CPU_Usage_Percent\": psutil.cpu_percent(interval=1),\n",
    "    \"Memory_Used_GB\": round(psutil.virtual_memory().used / (1024 ** 3), 2),\n",
    "    \"Duration_Sec\": vector_duration,\n",
    "    \"Notes\": f\"TF-IDF shape: {X.shape}\"\n",
    "})\n",
    "\n",
    "# Step 3: Label Encoding\n",
    "label_map = {\"Positive\": 1, \"Neutral\": 0, \"Negative\": 2}\n",
    "y = pdf[\"sentiment\"].map(label_map)\n",
    "\n",
    "# Step 4: Split data\n",
    "from sklearn.model_selection import train_test_split\n",
    "split_start = time.time()\n",
    "pdf = pdf.sample(frac=1, random_state=42).reset_index(drop=True)  # shuffle for fairness\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=False)\n",
    "split_duration = round(time.time() - split_start, 2)\n",
    "eval_log.append({\n",
    "    \"Step\": \"Train-Test Split\",\n",
    "    \"Time\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "    \"CPU_Usage_Percent\": psutil.cpu_percent(interval=1),\n",
    "    \"Memory_Used_GB\": round(psutil.virtual_memory().used / (1024 ** 3), 2),\n",
    "    \"Duration_Sec\": split_duration,\n",
    "    \"Notes\": f\"Train={X_train.shape[0]}, Test={X_test.shape[0]}\"\n",
    "})\n",
    "\n",
    "# Step 5: Model Training & Evaluation\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(C=1.0, penalty='l2', solver='liblinear', max_iter=1000),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=150, max_depth=15, min_samples_split=5, random_state=42),\n",
    "    \"Naive Bayes\": MultinomialNB(alpha=0.5),\n",
    "    \"Linear SVM\": LinearSVC(C=0.8, max_iter=2000)\n",
    "}\n",
    "\n",
    "best_accuracy = 0\n",
    "best_model = None\n",
    "best_model_name = \"\"\n",
    "best_report = \"\"\n",
    "\n",
    "for name, model in models.items():\n",
    "    model_start = time.time()\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred, zero_division=0)\n",
    "\n",
    "    print(f\"=== {name} ===\")\n",
    "    print(\"Accuracy:\", acc)\n",
    "    print(report)\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    eval_log.append({\n",
    "        \"Step\": f\"Train & Evaluate {name}\",\n",
    "        \"Time\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "        \"CPU_Usage_Percent\": psutil.cpu_percent(interval=1),\n",
    "        \"Memory_Used_GB\": round(psutil.virtual_memory().used / (1024 ** 3), 2),\n",
    "        \"Duration_Sec\": round(time.time() - model_start, 2),\n",
    "        \"Notes\": f\"Accuracy: {acc:.4f}\"\n",
    "    })\n",
    "\n",
    "    if acc > best_accuracy:\n",
    "        best_accuracy = acc\n",
    "        best_model_name = name\n",
    "        best_model = model\n",
    "        best_report = report\n",
    "\n",
    "# Step 6: Write evaluation logs to Delta table\n",
    "try:\n",
    "    eval_df = spark.createDataFrame(pd.DataFrame(eval_log))\n",
    "    eval_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"evaluation.model_training_logs\")\n",
    "    print(\"Evaluation logs written to Delta table: evaluation.model_training_logs\")\n",
    "except Exception as e:\n",
    "    print(f\"Failed to save evaluation logs: {e}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0934a8cf-d840-4ff5-bd5d-c36c90788792",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>Step</th><th>Time</th><th>CPU_Usage_Percent</th><th>Memory_Used_GB</th><th>Duration_Sec</th><th>Notes</th></tr></thead><tbody><tr><td>Train & Evaluate Linear SVM</td><td>2025-06-06 22:34:29</td><td>19.3</td><td>10.89</td><td>1.07</td><td>Accuracy: 0.9022</td></tr><tr><td>Train & Evaluate Naive Bayes</td><td>2025-06-06 22:34:28</td><td>24.4</td><td>10.88</td><td>1.01</td><td>Accuracy: 0.8109</td></tr><tr><td>Train & Evaluate Random Forest</td><td>2025-06-06 22:34:27</td><td>15.9</td><td>10.89</td><td>2.9</td><td>Accuracy: 0.7591</td></tr><tr><td>Train & Evaluate Logistic Regression</td><td>2025-06-06 22:34:24</td><td>18.3</td><td>10.89</td><td>1.08</td><td>Accuracy: 0.8964</td></tr><tr><td>Train-Test Split</td><td>2025-06-06 22:34:23</td><td>17.9</td><td>10.89</td><td>0.0</td><td>Train=9116, Test=2279</td></tr><tr><td>TF-IDF Vectorization</td><td>2025-06-06 22:34:22</td><td>20.4</td><td>10.89</td><td>0.16</td><td>TF-IDF shape: (11395, 1000)</td></tr><tr><td>Load Data</td><td>2025-06-06 22:34:21</td><td>20.9</td><td>10.89</td><td>1.03</td><td>Loaded 11395 rows</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "Train & Evaluate Linear SVM",
         "2025-06-06 22:34:29",
         19.3,
         10.89,
         1.07,
         "Accuracy: 0.9022"
        ],
        [
         "Train & Evaluate Naive Bayes",
         "2025-06-06 22:34:28",
         24.4,
         10.88,
         1.01,
         "Accuracy: 0.8109"
        ],
        [
         "Train & Evaluate Random Forest",
         "2025-06-06 22:34:27",
         15.9,
         10.89,
         2.9,
         "Accuracy: 0.7591"
        ],
        [
         "Train & Evaluate Logistic Regression",
         "2025-06-06 22:34:24",
         18.3,
         10.89,
         1.08,
         "Accuracy: 0.8964"
        ],
        [
         "Train-Test Split",
         "2025-06-06 22:34:23",
         17.9,
         10.89,
         0.0,
         "Train=9116, Test=2279"
        ],
        [
         "TF-IDF Vectorization",
         "2025-06-06 22:34:22",
         20.4,
         10.89,
         0.16,
         "TF-IDF shape: (11395, 1000)"
        ],
        [
         "Load Data",
         "2025-06-06 22:34:21",
         20.9,
         10.89,
         1.03,
         "Loaded 11395 rows"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "Step",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Time",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "CPU_Usage_Percent",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "Memory_Used_GB",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "Duration_Sec",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "Notes",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "eval_logs_df = spark.sql(\"SELECT * FROM evaluation.model_training_logs ORDER BY Time DESC LIMIT 20\")\n",
    "display(eval_logs_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "63053936-6712-439e-a82a-6ab3c265958a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "4. Pipeline Monitoring & Evaluation Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "db4ccf70-5d23-4210-bd18-e6cb5a3aeec1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pipeline_logs = spark.sql(\"SELECT * FROM evaluation.pipeline_logs ORDER BY Time DESC LIMIT 100\")\n",
    "sentiment_logs = spark.sql(\"SELECT * FROM evaluation.sentiment_analysis_logs ORDER BY Time DESC LIMIT 50\")\n",
    "training_logs = spark.sql(\"SELECT * FROM evaluation.model_training_logs ORDER BY Time DESC LIMIT 100\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "40065363-d7e6-4460-b7aa-c174835562ac",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    \"Model\": [\"Logistic Regression\", \"Random Forest\", \"Naive Bayes\", \"Linear SVM\"],\n",
    "    \"Accuracy\": [0.8964, 0.7591, 0.8109, 0.9022]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "colors = {\n",
    "    \"Logistic Regression\": \"#1f77b4\",  \n",
    "    \"Random Forest\": \"#ff7f0e\",        \n",
    "    \"Naive Bayes\": \"#2ca02c\",          \n",
    "    \"Linear SVM\": \"#d62728\"            \n",
    "}\n",
    "\n",
    "df[\"Color\"] = df[\"Model\"].map(colors)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "bars = plt.bar(df[\"Model\"], df[\"Accuracy\"], color=df[\"Color\"])\n",
    "\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, height + 0.01, f'{height:.4f}',\n",
    "             ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "plt.title(\"Model Accuracy Comparison\", fontsize=14)\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.ylim(0, 1)\n",
    "plt.xticks(rotation=15)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.4)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 8616803679042678,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Evaluation",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}